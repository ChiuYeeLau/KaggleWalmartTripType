{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV \n",
    "import xgboost as xgb\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sampleSub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# fill in missing values by Null (in DepartmentDescription and FinelineNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()\n",
    "from copy import deepcopy\n",
    "ScanCountTrain = deepcopy(train.ScanCount)\n",
    "\n",
    "train.DepartmentDescription = train.DepartmentDescription.fillna('Null')\n",
    "test.DepartmentDescription = test.DepartmentDescription.fillna('Null')\n",
    "\n",
    "train.FinelineNumber = train.FinelineNumber.fillna(-1)\n",
    "test.FinelineNumber = test.FinelineNumber.fillna(-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get train categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 999] 38\n"
     ]
    }
   ],
   "source": [
    "trainLabels = [3, 4, 5, 6, 7, 8, 9, 12, 14, 15,\n",
    "               18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
    "               28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
    "               38, 39, 40, 41, 42, 43, 44, 999]\n",
    "print trainLabels, len(trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.TripType = train.TripType.map(lambda x:trainLabels.index(x))\n",
    "weekdays = list(set(train.Weekday))\n",
    "train.Weekday = train.Weekday.map(lambda x:weekdays.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripType</th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Upc</th>\n",
       "      <th>ScanCount</th>\n",
       "      <th>DepartmentDescription</th>\n",
       "      <th>FinelineNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>68113152929</td>\n",
       "      <td>-1</td>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>60538815980</td>\n",
       "      <td>1</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7410811099</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2238403510</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2006613744</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TripType  VisitNumber  Weekday          Upc  ScanCount  \\\n",
       "0        37            5        2  68113152929         -1   \n",
       "1        22            7        2  60538815980          1   \n",
       "2        22            7        2   7410811099          1   \n",
       "3        18            8        2   2238403510          2   \n",
       "4        18            8        2   2006613744          2   \n",
       "\n",
       "   DepartmentDescription  FinelineNumber  \n",
       "0     FINANCIAL SERVICES            1000  \n",
       "1                  SHOES            8931  \n",
       "2          PERSONAL CARE            4504  \n",
       "3  PAINT AND ACCESSORIES            3565  \n",
       "4  PAINT AND ACCESSORIES            1017  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dict for visitnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainVisit = train.VisitNumber.as_matrix()\n",
    "rowNum = np.array(range(train.shape[0]))\n",
    "visitNum = zip(rowNum, trainVisit)\n",
    "\n",
    "from collections import OrderedDict\n",
    "trainDict = OrderedDict()\n",
    "for r, v in visitNum:\n",
    "    if v in trainDict: \n",
    "        trainDict[v].append(r)\n",
    "    else: trainDict[v] = [r]\n",
    "        \n",
    "testVisit = test.VisitNumber.as_matrix()\n",
    "rowNum = np.array(range(test.shape[0]))\n",
    "visitNum = zip(rowNum, testVisit)\n",
    "\n",
    "testDict = OrderedDict()\n",
    "for r, v in visitNum:\n",
    "    if v in testDict: \n",
    "        testDict[v].append(r)\n",
    "    else: testDict[v] = [r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default Logodds: distribution of trip types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 22, 18, ..., 31, 31,  5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainTargetAgg = train.groupby(['VisitNumber'])['TripType'].mean()\n",
    "trainTarget = trainTargetAgg.as_matrix()\n",
    "trainTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = {}\n",
    "for item in trainTarget:\n",
    "    b[item] = b.get(item, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.80772206e-02,   3.61644752e-03,   4.80067730e-02,\n",
       "         1.33474089e-02,   6.01208270e-02,   1.27108723e-01,\n",
       "         9.89192466e-02,   2.81163116e-03,   4.18086418e-05,\n",
       "         1.02222129e-02,   5.73823609e-03,   3.91956017e-03,\n",
       "         6.65802621e-03,   6.69983486e-03,   9.69960491e-03,\n",
       "         1.45285030e-03,   2.72696866e-02,   3.86520894e-02,\n",
       "         5.25743671e-03,   8.20494596e-03,   5.14246295e-03,\n",
       "         4.52578548e-03,   1.12987855e-02,   6.20858331e-03,\n",
       "         2.07370864e-02,   1.37445910e-02,   7.51510337e-03,\n",
       "         2.12178857e-02,   3.14087422e-02,   2.91406234e-02,\n",
       "         3.04366913e-02,   1.03434580e-01,   6.40717436e-02,\n",
       "         6.09360955e-03,   1.94201141e-02,   9.11428392e-03,\n",
       "         1.24067145e-02,   8.82580429e-02])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripDist = np.array(b.values())/float(len(trainTarget))\n",
    "tripDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scanCountTrain = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scanCountTrain.ScanCount = map(lambda x: 1 if x > 0 else 0, scanCountTrain.ScanCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scanTripCount = scanCountTrain.groupby(['ScanCount', 'TripType']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tripCount = scanCountTrain.groupby(['TripType']).size()\n",
    "scanCount = scanCountTrain.groupby(['ScanCount']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScanCount\n",
       "0     15458\n",
       "1    631596\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "defaultLogodds = tripDist\n",
    "# np.log(tripCount/len(train) * 1.0) - np.log(1.0 - tripCount/len(train) * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scanCountLogodds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "scanCountLogodds[0] = deepcopy(defaultLogodds)\n",
    "scanCountLogodds[1] = deepcopy(defaultLogodds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = sorted(train['TripType'].unique())\n",
    "for trip in scanTripCount[0].keys():\n",
    "    PA = scanTripCount[0][trip]/float(scanCount[0])\n",
    "    scanCountLogodds[0][categories.index(trip)] = PA\n",
    "    # np.log(PA) - np.log(1.0 - PA)\n",
    "scanCountLogodds[0] = pd.Series(scanCountLogodds[0])\n",
    "scanCountLogodds[0].index = range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for trip in scanTripCount[1].keys():\n",
    "    PA = scanTripCount[1][trip]/float(scanCount[1])\n",
    "    scanCountLogodds[1][categories.index(trip)] = PA\n",
    "    # np.log(PA) - np.log(1.0 - PA)\n",
    "scanCountLogodds[1] = pd.Series(scanCountLogodds[1])\n",
    "scanCountLogodds[1].index = range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scanCountLogodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categories\n",
    "# tripCount\n",
    "departTripCount = train.groupby(['DepartmentDescription', 'TripType']).size()\n",
    "departCount = train.groupby(['DepartmentDescription']).size()\n",
    "departLogodds = {}\n",
    "departTrain = sorted(train['DepartmentDescription'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# departLogodds\n",
    "for dp in departTrain:\n",
    "    departLogodds[dp] = deepcopy(defaultLogodds)\n",
    "    for trip in departTripCount[dp].keys():\n",
    "        PA = departTripCount[dp][trip]/float(departCount[dp])\n",
    "        departLogodds[dp][categories.index(trip)] = PA\n",
    "        # np.log(PA) - np.log(1.0 - PA)\n",
    "    departLogodds[dp] = pd.Series(departLogodds[dp])\n",
    "    departLogodds[dp].index = range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categories\n",
    "# tripCount\n",
    "flTripCount = train.groupby(['FinelineNumber', 'TripType']).size()\n",
    "flCount = train.groupby(['FinelineNumber']).size()\n",
    "flLogodds = {}\n",
    "flTrain = sorted(train['FinelineNumber'].unique())\n",
    "\n",
    "for fl in flTrain:\n",
    "    fl = int(fl)\n",
    "    flLogodds[fl] = deepcopy(defaultLogodds)\n",
    "    for trip in flTripCount[fl].keys():\n",
    "        PA = flTripCount[fl][trip]/float(flCount[fl])\n",
    "        flLogodds[fl][categories.index(trip)] = PA\n",
    "        # np.log(PA) - np.log(1.0 - PA)\n",
    "    flLogodds[fl] = pd.Series(flLogodds[fl])\n",
    "    flLogodds[fl].index = range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekdayTripCount = train.groupby(['Weekday', 'TripType']).size()\n",
    "wdCount = train.groupby(['Weekday']).size()\n",
    "wdLogodds = {}\n",
    "wdTrain = sorted(train['Weekday'].unique())\n",
    "\n",
    "for wd in wdTrain:\n",
    "    wdLogodds[wd] = deepcopy(defaultLogodds)\n",
    "    for trip in weekdayTripCount[wd].keys():\n",
    "        PA = weekdayTripCount[wd][trip]/float(wdCount[wd])\n",
    "        wdLogodds[wd][categories.index(trip)] = PA\n",
    "        # np.log(PA) - np.log(1.0 - PA)\n",
    "    wdLogodds[wd] = pd.Series(wdLogodds[wd])\n",
    "    wdLogodds[wd].index = range(len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainTargetAgg = train.groupby(['VisitNumber'])['TripType'].mean()\n",
    "# trainTarget = trainTargetAgg.as_matrix()\n",
    "# trainTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5333 3246\n"
     ]
    }
   ],
   "source": [
    "finelineReturn = list(set(train[train.ScanCount < 0].FinelineNumber).union(set(test[test.ScanCount < 0].FinelineNumber)))\n",
    "finelineReturn = map(lambda x:int(x), finelineReturn)\n",
    "finelineBuy = list(set(train[train.ScanCount > 0].FinelineNumber).union(set(test[test.ScanCount > 0].FinelineNumber)))\n",
    "finelineBuy = map(lambda x:int(x), finelineBuy)\n",
    "print len(finelineBuy), len(finelineReturn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Weekdays = list(set(train.Weekday))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5668\n"
     ]
    }
   ],
   "source": [
    "Depart = list(set(train.DepartmentDescription).union(set(test.DepartmentDescription)))\n",
    "\n",
    "length = len(Weekdays) + len(Depart) * 2 + len(finelineBuy) + len(trainLabels) * 5\n",
    "print length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainFeat = np.zeros((len(set(train.VisitNumber)), length))\n",
    "testFeat = np.zeros((len(set(test.VisitNumber)), length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95674, 5668)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 -> 6, 7 -> 44, 45 -> 82, 83 -> 120, 121 -> 158, 159 -> 196, 197 -> 265, 266 -> 334, 335 -> 5667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = trainDict.keys()\n",
    "for i in range(len(trainDict)):\n",
    "    key = keys[i]\n",
    "    for val in trainDict[key]:\n",
    "        idx = Weekdays.index(train.Weekday[val])\n",
    "        trainFeat[i][idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[647052, 647053]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = testDict.keys()\n",
    "for i in range(len(testDict)):\n",
    "    key = keys[i]\n",
    "    for val in testDict[key]:\n",
    "        idx = Weekdays.index(test.Weekday[val])\n",
    "        testFeat[i][idx] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## tripDist Logodds\n",
    "keys = trainDict.keys()\n",
    "for i in range(len(trainDict)):\n",
    "    trainFeat[i][7 : 45] = tripDist\n",
    "        \n",
    "keys = testDict.keys()\n",
    "for i in range(len(testDict)):\n",
    "    testFeat[i][7 : 45] = tripDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weekday Logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = trainDict.keys()\n",
    "for i in range(len(trainDict)):\n",
    "    key = keys[i]\n",
    "    for val in trainDict[key]:\n",
    "        wd = train.Weekday[val]\n",
    "        trainFeat[i][7 : 45] += wdLogodds[wd]\n",
    "        \n",
    "keys = testDict.keys()\n",
    "for i in range(len(testDict)):\n",
    "    key = keys[i]\n",
    "    for val in testDict[key]:\n",
    "        wd = test.Weekday[val]\n",
    "        testFeat[i][7 : 45] += wdLogodds[wd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScanCount Logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripType</th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Upc</th>\n",
       "      <th>ScanCount</th>\n",
       "      <th>DepartmentDescription</th>\n",
       "      <th>FinelineNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>68113152929</td>\n",
       "      <td>-1</td>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>60538815980</td>\n",
       "      <td>1</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7410811099</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>4504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2238403510</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2006613744</td>\n",
       "      <td>2</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TripType  VisitNumber Weekday          Upc  ScanCount  \\\n",
       "0        37            5  Friday  68113152929         -1   \n",
       "1        22            7  Friday  60538815980          1   \n",
       "2        22            7  Friday   7410811099          1   \n",
       "3        18            8  Friday   2238403510          2   \n",
       "4        18            8  Friday   2006613744          2   \n",
       "\n",
       "   DepartmentDescription  FinelineNumber  \n",
       "0     FINANCIAL SERVICES            1000  \n",
       "1                  SHOES            8931  \n",
       "2          PERSONAL CARE            4504  \n",
       "3  PAINT AND ACCESSORIES            3565  \n",
       "4  PAINT AND ACCESSORIES            1017  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ScanCount = ScanCountTrain\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = trainDict.keys()\n",
    "for i in range(len(trainDict)):\n",
    "    key = keys[i]\n",
    "    for val in trainDict[key]:\n",
    "        scancount = train.ScanCount[val]\n",
    "        if scancount > 0:\n",
    "            flag = 1\n",
    "        else:\n",
    "            flag = 0\n",
    "            \n",
    "        trainFeat[i][7 : 45] += scanCountLogodds[flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = testDict.keys()\n",
    "for i in range(len(testDict)):\n",
    "    key = keys[i]\n",
    "    for val in testDict[key]:\n",
    "        scancount = test.ScanCount[val]\n",
    "        if scancount > 0:\n",
    "            flag = 1\n",
    "        else:\n",
    "            flag = 0\n",
    "            \n",
    "        testFeat[i][7 : 45] += scanCountLogodds[flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depart Logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = trainDict.keys()\n",
    "for i in range(len(trainDict)):\n",
    "    key = keys[i]\n",
    "    for val in trainDict[key]:\n",
    "        dp = train.DepartmentDescription[val]\n",
    "        trainFeat[i][45 : 83] += departLogodds[dp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDP = sorted(test.DepartmentDescription.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DepartmentDescription\n",
       "1-HR PHOTO                      394\n",
       "ACCESSORIES                    1420\n",
       "AUTOMOTIVE                     5459\n",
       "BAKERY                         7165\n",
       "BATH AND SHOWER                4665\n",
       "BEAUTY                        15223\n",
       "BEDDING                        2203\n",
       "BOOKS AND MAGAZINES             909\n",
       "BOYS WEAR                      3886\n",
       "BRAS & SHAPEWEAR               2018\n",
       "CAMERAS AND SUPPLIES            247\n",
       "CANDY, TOBACCO, COOKIES       10310\n",
       "CELEBRATION                    8635\n",
       "COMM BREAD                    15688\n",
       "CONCEPT STORES                   49\n",
       "COOK AND DINE                  7788\n",
       "DAIRY                         44824\n",
       "DSD GROCERY                   68860\n",
       "ELECTRONICS                    3361\n",
       "FABRICS AND CRAFTS             5170\n",
       "FINANCIAL SERVICES            10857\n",
       "FROZEN FOODS                  21890\n",
       "FURNITURE                       444\n",
       "GIRLS WEAR, 4-6X  AND 7-14     4628\n",
       "GROCERY DRY GOODS             72335\n",
       "HARDWARE                       4885\n",
       "HOME DECOR                     4069\n",
       "HOME MANAGEMENT                6297\n",
       "HORTICULTURE AND ACCESS        3040\n",
       "HOUSEHOLD CHEMICALS/SUPP      24602\n",
       "                              ...  \n",
       "LAWN AND GARDEN                5521\n",
       "LIQUOR,WINE,BEER               3781\n",
       "MEAT - FRESH & FROZEN          9936\n",
       "MEDIA AND GAMING               2061\n",
       "MENS WEAR                     12171\n",
       "MENSWEAR                        351\n",
       "Null                           1328\n",
       "OFFICE SUPPLIES                6793\n",
       "OPTICAL - FRAMES                594\n",
       "OPTICAL - LENSES                 97\n",
       "OTHER DEPARTMENTS                34\n",
       "PAINT AND ACCESSORIES          1822\n",
       "PERSONAL CARE                 41607\n",
       "PETS AND SUPPLIES              9694\n",
       "PHARMACY OTC                  23293\n",
       "PHARMACY RX                    2784\n",
       "PLAYERS AND ELECTRONICS         669\n",
       "PLUS AND MATERNITY              644\n",
       "PRE PACKED DELI                9276\n",
       "PRODUCE                       50928\n",
       "SEAFOOD                        2135\n",
       "SEASONAL                         47\n",
       "SERVICE DELI                  10049\n",
       "SHEER HOSIERY                   514\n",
       "SHOES                          6214\n",
       "SLEEPWEAR/FOUNDATIONS          2463\n",
       "SPORTING GOODS                 5031\n",
       "SWIMWEAR/OUTERWEAR              870\n",
       "TOYS                           6135\n",
       "WIRELESS                       1810\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDPCount = test.groupby([\"DepartmentDescription\"]).size()\n",
    "newDPCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyNewDP = set(newDP + departTrain) - set(departTrain)\n",
    "onlyNewDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = testDict.keys()\n",
    "for i in range(len(testDict)):\n",
    "    key = keys[i]\n",
    "    for val in testDict[key]:\n",
    "        dp = test.DepartmentDescription[val]\n",
    "        testFeat[i][45 : 83] += departLogodds[dp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FL Logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = trainDict.keys()\n",
    "for i in range(len(trainDict)):\n",
    "    key = keys[i]\n",
    "    for val in trainDict[key]:\n",
    "        fl = train.FinelineNumber[val]\n",
    "        trainFeat[i][83 : 121] += flLogodds[fl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newFL = sorted(test.FinelineNumber.unique())\n",
    "newFLCount = test.groupby([\"FinelineNumber\"]).size()\n",
    "onlyNewFL = set(newFL + flTrain) - set(flTrain)\n",
    "# onlyNewFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fl in onlyNewFL:\n",
    "    flLogodds[fl] = deepcopy(defaultLogodds)\n",
    "    flLogodds[fl].index = range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = testDict.keys()\n",
    "for i in range(len(testDict)):\n",
    "    key = keys[i]\n",
    "    for val in testDict[key]:\n",
    "        fl = test.FinelineNumber[val]\n",
    "        testFeat[i][83 : 121] += flLogodds[fl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinelineNumber for buying/Returning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = trainDict.keys()\n",
    "for i in range(len(trainDict)):\n",
    "    key = keys[i]\n",
    "    for val in trainDict[key]:\n",
    "        scancount = train.ScanCount[val]\n",
    "        # finelineDepart = (train.DepartmentDescription[val], train.FinelineNumber[val])\n",
    "        depart = train.DepartmentDescription[val]\n",
    "        fineline = int(train.FinelineNumber[val])\n",
    "        \n",
    "        if scancount < 0:\n",
    "            idxDepart = Depart.index(depart) + 121\n",
    "            trainFeat[i][idxDepart] += 1\n",
    "            # idxFineline = finelineReturn.index(fineline) + 7 + len(Depart)\n",
    "        else:\n",
    "            idxDepart = Depart.index(depart) + 190\n",
    "            idxFineline = finelineBuy.index(fineline) + 259\n",
    "            trainFeat[i][idxDepart] += 1\n",
    "            trainFeat[i][idxFineline] += scancount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = testDict.keys()\n",
    "for i in range(len(testDict)):\n",
    "    key = keys[i]\n",
    "    for val in testDict[key]:\n",
    "        scancount = test.ScanCount[val]\n",
    "        # finelineDepart = (test.DepartmentDescription[val], test.FinelineNumber[val])\n",
    "        \n",
    "        depart = test.DepartmentDescription[val]\n",
    "        fineline = int(test.FinelineNumber[val])\n",
    "        \n",
    "        if scancount < 0:\n",
    "            idxDepart = Depart.index(depart) + 121\n",
    "            testFeat[i][idxDepart] += 1\n",
    "            # idxFineline = finelineReturn.index(fineline) + 7 + len(Depart)\n",
    "        else:\n",
    "            idxDepart = Depart.index(depart) + 190\n",
    "            idxFineline = finelineBuy.index(fineline) + 259\n",
    "            testFeat[i][idxDepart] += 1\n",
    "            testFeat[i][idxFineline] += scancount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2270737836409342"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainFeat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Train xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95674L, 11156L)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncvIdx = random.sample(xrange(trainFeat.shape[0]), 10000)\\ncvX = trainFeat[cvIdx,]\\ncvY = trainTarget[cvIdx]\\ntrainIdx = [x for x in xrange(trainFeat.shape[0]) if x not in cvIdx]\\nnp.random.shuffle(trainIdx)\\ntrainX = trainFeat[trainIdx,]\\ntrainY = trainTarget[trainIdx,]\\ndtrain = xgb.DMatrix(trainX, label = trainY)\\ndtest = xgb.DMatrix(cvX, label = cvY)\\n\\nparam = {\\'max_depth\\': 6, \\n         \\'eta\\': 0.25, \\n         \\'silent\\': 1, \\n         \\'objective\\': \\'multi:softprob\\',\\n         \\'eval_metric\\': \"mlogloss\",\\n         \\'min_child_weight\\': 1,\\n         \\'subsample\\': 0.6,\\n         \\'colsample_bytree\\': 0.5,\\n         \\'num_class\\': 38\\n        }\\n        \\nwatchlist  = [(dtrain,\\'train\\'), (dtest,\\'eval\\')]\\n\\nnumRound = 1000000\\n\\nxgbModel = xgb.train(param, dtrain, numRound, watchlist, early_stopping_rounds = 30)\\n\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cvIdx = random.sample(xrange(trainFeat.shape[0]), 10000)\n",
    "cvX = trainFeat[cvIdx,]\n",
    "cvY = trainTarget[cvIdx]\n",
    "trainIdx = [x for x in xrange(trainFeat.shape[0]) if x not in cvIdx]\n",
    "np.random.shuffle(trainIdx)\n",
    "trainX = trainFeat[trainIdx,]\n",
    "trainY = trainTarget[trainIdx,]\n",
    "dtrain = xgb.DMatrix(trainX, label = trainY)\n",
    "dtest = xgb.DMatrix(cvX, label = cvY)\n",
    "\n",
    "param = {'max_depth': 6, \n",
    "         'eta': 0.25, \n",
    "         'silent': 1, \n",
    "         'objective': 'multi:softprob',\n",
    "         'eval_metric': \"mlogloss\",\n",
    "         'min_child_weight': 1,\n",
    "         'subsample': 0.6,\n",
    "         'colsample_bytree': 0.5,\n",
    "         'num_class': 38\n",
    "        }\n",
    "        \n",
    "watchlist  = [(dtrain,'train'), (dtest,'eval')]\n",
    "\n",
    "numRound = 1000000\n",
    "\n",
    "xgbModel = xgb.train(param, dtrain, numRound, watchlist, early_stopping_rounds = 30)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntestPred = model.predict(xgb.DMatrix(testFeat))\\nmySampleSub = SampleSub\\nmySampleSub.ix[:,1:39] = testPred\\nmySampleSub.VisitNumber = map(lambda x: int(x), mySampleSub.VisitNumber)\\nmySampleSub.to_csv(\"xgbSub.csv\", index = False)\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "testPred = model.predict(xgb.DMatrix(testFeat))\n",
    "mySampleSub = SampleSub\n",
    "mySampleSub.ix[:,1:39] = testPred\n",
    "mySampleSub.VisitNumber = map(lambda x: int(x), mySampleSub.VisitNumber)\n",
    "mySampleSub.to_csv(\"xgbSub.csv\", index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Lasagne Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import TrainSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers0 = [('input', InputLayer),\n",
    "           ('dense', DenseLayer),\n",
    "           ('dropout', DropoutLayer),\n",
    "           ('output', DenseLayer)]\n",
    "\n",
    "numClasses = 38\n",
    "numFeatures = trainFeat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------0---------\n",
      "# Neural Network with 1441574 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name       size\n",
      "---  -------  ------\n",
      "  0  input      5592\n",
      "  1  dense       256\n",
      "  2  dropout     256\n",
      "  3  output       38\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m2.17978\u001b[0m       \u001b[32m1.51802\u001b[0m      1.43594      0.61405  33.15s\n",
      "      2       \u001b[36m1.40150\u001b[0m       \u001b[32m1.23487\u001b[0m      1.13494      0.65651  19.64s\n",
      "      3       \u001b[36m1.20957\u001b[0m       \u001b[32m1.11737\u001b[0m      1.08251      0.67193  20.12s\n",
      "      4       \u001b[36m1.10959\u001b[0m       \u001b[32m1.04809\u001b[0m      1.05868      0.68477  19.67s\n",
      "      5       \u001b[36m1.04749\u001b[0m       \u001b[32m1.00231\u001b[0m      1.04508      0.69091  19.36s\n",
      "      6       \u001b[36m1.00255\u001b[0m       \u001b[32m0.96602\u001b[0m      1.03781      0.69823  19.16s\n",
      "      7       \u001b[36m0.96500\u001b[0m       \u001b[32m0.94182\u001b[0m      1.02462      0.70384  20.25s\n",
      "      8       \u001b[36m0.93359\u001b[0m       \u001b[32m0.91635\u001b[0m      1.01881      0.71002  19.52s\n",
      "      9       \u001b[36m0.90894\u001b[0m       \u001b[32m0.89470\u001b[0m      1.01591      0.71503  18.81s\n",
      "     10       \u001b[36m0.88461\u001b[0m       \u001b[32m0.87859\u001b[0m      1.00685      0.71973  18.79s\n",
      "     11       \u001b[36m0.86435\u001b[0m       \u001b[32m0.86323\u001b[0m      1.00130      0.72131  19.16s\n",
      "     12       \u001b[36m0.84519\u001b[0m       \u001b[32m0.85018\u001b[0m      0.99414      0.72403  19.91s\n",
      "     13       \u001b[36m0.82737\u001b[0m       \u001b[32m0.83759\u001b[0m      0.98780      0.72834  19.02s\n",
      "     14       \u001b[36m0.81339\u001b[0m       \u001b[32m0.82656\u001b[0m      0.98406      0.73044  19.68s\n",
      "     15       \u001b[36m0.79861\u001b[0m       \u001b[32m0.81595\u001b[0m      0.97874      0.73273  21.47s\n",
      "     16       \u001b[36m0.78487\u001b[0m       \u001b[32m0.80563\u001b[0m      0.97424      0.73565  22.62s\n",
      "     17       \u001b[36m0.77337\u001b[0m       \u001b[32m0.79598\u001b[0m      0.97160      0.73950  20.36s\n",
      "     18       \u001b[36m0.75897\u001b[0m       \u001b[32m0.78808\u001b[0m      0.96306      0.74086  19.90s\n",
      "     19       \u001b[36m0.74945\u001b[0m       \u001b[32m0.78065\u001b[0m      0.96004      0.74223  20.50s\n",
      "     20       \u001b[36m0.73669\u001b[0m       \u001b[32m0.77446\u001b[0m      0.95123      0.74348  20.42s\n",
      "     21       \u001b[36m0.72657\u001b[0m       \u001b[32m0.76598\u001b[0m      0.94854      0.74462  19.99s\n",
      "     22       \u001b[36m0.71370\u001b[0m       \u001b[32m0.76056\u001b[0m      0.93839      0.74608  20.67s\n",
      "     23       \u001b[36m0.70437\u001b[0m       \u001b[32m0.75530\u001b[0m      0.93257      0.74755  20.16s\n",
      "     24       \u001b[36m0.69673\u001b[0m       \u001b[32m0.75040\u001b[0m      0.92849      0.74807  19.73s\n",
      "     25       \u001b[36m0.68657\u001b[0m       \u001b[32m0.74335\u001b[0m      0.92360      0.75004  19.66s\n",
      "     26       \u001b[36m0.67691\u001b[0m       \u001b[32m0.73960\u001b[0m      0.91525      0.75068  19.97s\n",
      "     27       \u001b[36m0.66864\u001b[0m       \u001b[32m0.73685\u001b[0m      0.90743      0.75069  20.33s\n",
      "     28       \u001b[36m0.66202\u001b[0m       \u001b[32m0.73089\u001b[0m      0.90578      0.75289  20.12s\n",
      "     29       \u001b[36m0.65324\u001b[0m       \u001b[32m0.72523\u001b[0m      0.90073      0.75529  20.24s\n",
      "     30       \u001b[36m0.64287\u001b[0m       0.72538      0.88625      0.75402  20.02s\n",
      "     31       \u001b[36m0.63929\u001b[0m       \u001b[32m0.71957\u001b[0m      0.88843      0.75585  19.75s\n",
      "     32       \u001b[36m0.62923\u001b[0m       \u001b[32m0.71448\u001b[0m      0.88067      0.75804  19.85s\n",
      "     33       \u001b[36m0.62358\u001b[0m       \u001b[32m0.71077\u001b[0m      0.87733      0.75847  20.00s\n",
      "     34       \u001b[36m0.61817\u001b[0m       \u001b[32m0.70788\u001b[0m      0.87327      0.76055  21.67s\n",
      "     35       \u001b[36m0.60973\u001b[0m       \u001b[32m0.70522\u001b[0m      0.86458      0.76086  20.90s\n",
      "     36       \u001b[36m0.60427\u001b[0m       \u001b[32m0.70366\u001b[0m      0.85875      0.76022  20.06s\n",
      "     37       \u001b[36m0.59591\u001b[0m       \u001b[32m0.70164\u001b[0m      0.84930      0.76222  19.98s\n",
      "     38       \u001b[36m0.59076\u001b[0m       \u001b[32m0.70130\u001b[0m      0.84237      0.76003  19.92s\n",
      "     39       \u001b[36m0.58708\u001b[0m       \u001b[32m0.69720\u001b[0m      0.84205      0.76347  19.99s\n",
      "     40       \u001b[36m0.57910\u001b[0m       \u001b[32m0.69292\u001b[0m      0.83574      0.76461  20.00s\n",
      "     41       \u001b[36m0.57339\u001b[0m       \u001b[32m0.69056\u001b[0m      0.83033      0.76525  20.03s\n",
      "     42       \u001b[36m0.56825\u001b[0m       \u001b[32m0.68713\u001b[0m      0.82698      0.76555  20.07s\n",
      "     43       \u001b[36m0.56030\u001b[0m       \u001b[32m0.68585\u001b[0m      0.81694      0.76537  20.04s\n",
      "     44       \u001b[36m0.55788\u001b[0m       \u001b[32m0.68552\u001b[0m      0.81380      0.76370  19.61s\n",
      "     45       \u001b[36m0.55000\u001b[0m       \u001b[32m0.68541\u001b[0m      0.80243      0.76518  19.94s\n",
      "     46       \u001b[36m0.54513\u001b[0m       \u001b[32m0.68185\u001b[0m      0.79949      0.76643  20.18s\n",
      "     47       \u001b[36m0.54114\u001b[0m       \u001b[32m0.68034\u001b[0m      0.79539      0.76788  19.99s\n",
      "     48       \u001b[36m0.53637\u001b[0m       \u001b[32m0.67735\u001b[0m      0.79187      0.76768  19.99s\n",
      "     49       \u001b[36m0.53124\u001b[0m       0.67887      0.78253      0.76717  20.03s\n",
      "     50       \u001b[36m0.52653\u001b[0m       \u001b[32m0.67599\u001b[0m      0.77890      0.76799  20.01s\n",
      "     51       \u001b[36m0.52143\u001b[0m       \u001b[32m0.67465\u001b[0m      0.77289      0.76759  20.05s\n",
      "     52       \u001b[36m0.51782\u001b[0m       \u001b[32m0.67236\u001b[0m      0.77016      0.76937  20.28s\n",
      "     53       \u001b[36m0.51448\u001b[0m       0.67304      0.76442      0.77010  20.09s\n",
      "     54       \u001b[36m0.50858\u001b[0m       0.67369      0.75492      0.76967  20.03s\n",
      "     55       \u001b[36m0.50560\u001b[0m       0.67345      0.75075      0.76916  19.94s\n",
      "     56       \u001b[36m0.49966\u001b[0m       \u001b[32m0.66875\u001b[0m      0.74715      0.76937  20.05s\n",
      "     57       \u001b[36m0.49391\u001b[0m       \u001b[32m0.66807\u001b[0m      0.73932      0.77000  20.18s\n",
      "     58       \u001b[36m0.49140\u001b[0m       \u001b[32m0.66656\u001b[0m      0.73722      0.76989  20.15s\n",
      "     59       \u001b[36m0.48765\u001b[0m       \u001b[32m0.66608\u001b[0m      0.73213      0.77071  19.96s\n",
      "     60       \u001b[36m0.48252\u001b[0m       0.66910      0.72116      0.77083  20.02s\n",
      "     61       \u001b[36m0.48031\u001b[0m       \u001b[32m0.66436\u001b[0m      0.72296      0.77197  20.25s\n",
      "     62       \u001b[36m0.47299\u001b[0m       0.66612      0.71007      0.77093  20.10s\n",
      "     63       \u001b[36m0.47159\u001b[0m       \u001b[32m0.66330\u001b[0m      0.71097      0.77114  20.16s\n"
     ]
    }
   ],
   "source": [
    "# 200, 0.5, 0.012, 0.7, 0.1/862\n",
    "# 92       0.48677       0.65550      0.74258      0.77797  33.23s\n",
    "# 200, 0.5, 0.015, 0.7, 0.1/862\n",
    "# 78       0.47839       0.65376      0.73175      0.77477  40.53s\n",
    "\n",
    "\n",
    "testPred = []\n",
    "\n",
    "for x in xrange(1):\n",
    "    print \"--------\" + str(x) + \"---------\"\n",
    "    random.seed(6)\n",
    "    net0 = NeuralNet(layers = layers0,\n",
    "               input_shape = (None, numFeatures),\n",
    "               dense_num_units = 256,\n",
    "               dropout_p = 0.3,\n",
    "               output_num_units = numClasses,\n",
    "               output_nonlinearity = softmax,\n",
    "               \n",
    "               update = nesterov_momentum,\n",
    "               update_learning_rate = 0.01,\n",
    "               update_momentum = 0.75,\n",
    "               \n",
    "               train_split = TrainSplit(0.1),\n",
    "               verbose = 1,\n",
    "               max_epochs = 63)\n",
    "    \n",
    "    trainTarget = trainTarget.astype(np.int32)\n",
    "    net0.fit(trainFeat, trainTarget)\n",
    "    \n",
    "    testPred.append(net0.predict_proba(testFeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testPredAvg = sum(testPred)/5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.32291812e-05,   2.11360421e-04,   1.17973341e-04, ...,\n",
       "          9.86548891e-04,   1.06986887e-04,   4.13904760e-04],\n",
       "       [  4.65699936e-04,   5.60867046e-04,   3.03647903e-04, ...,\n",
       "          6.64058002e-04,   1.08562736e-05,   6.88549100e-01],\n",
       "       [  5.82690140e-05,   3.12188332e-05,   2.97532317e-05, ...,\n",
       "          4.04316308e-07,   1.41511625e-08,   9.85141032e-01],\n",
       "       ..., \n",
       "       [  5.78649879e-05,   6.57875608e-05,   2.58685635e-05, ...,\n",
       "          2.54678114e-06,   2.28945880e-08,   4.71636761e-03],\n",
       "       [  4.89935357e-09,   2.12032193e-08,   4.24912144e-07, ...,\n",
       "          2.61271040e-03,   3.41455435e-03,   7.22595079e-07],\n",
       "       [  1.92729637e-07,   6.65004886e-10,   4.19563460e-09, ...,\n",
       "          5.12321960e-06,   4.19637742e-06,   8.42255474e-06]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredAvg\n",
    "testPred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testPredAvg[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mySampleSub = sampleSub\n",
    "mySampleSub.ix[:,1:39] = testPred[0]\n",
    "mySampleSub.VisitNumber = map(lambda x: int(x), mySampleSub.VisitNumber)\n",
    "mySampleSub.to_csv(\"nnSub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
